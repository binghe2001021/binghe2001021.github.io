## 环境搭建

根据NG的推荐，我选择了Octave作为学习工具，在ubuntu终端里使用以下命令安装：

> sudo apt-get update && sudo apt-get install octave

***

## 多元线性回归

（话说markdown写文字这么好用为什么不添加对数学公式的支持呢……我这种懒人只能直接截视频上的图了，侵删！）

![](http://p1.bpimg.com/4851/ab6476a553cc3ebc.png)

要理解这个公式很简单，α后面是第N维特征的导数，我们使用梯度下降逼近局部最优解的过程，其实就是一个不断更新θ的过程，对一个以xy为变量的代价函数的图来拟合曲线，实际上的变量是拟合曲线的斜率，也就是θ。

多元线性回归的特征缩放和学习速率与单元一致。

***

## Normal Equation

梯度下降往往只能解出局部最优，而Normal Equation则能一次性解出所有这样的点，它的原理很简单，即通过求解“偏导数为θ”来得到这些最优点，因为偏导数为θ的时候函数肯定处在一个极值点，课程给出了一个用矩阵计算的简便的公式：

![](http://p1.bpimg.com/4851/23d56deb4abcaf96.png)

其中X是包含有每条数据所有特征的矩阵，y是预测值的列矩阵，θ是结果矩阵，证明过程略。

***

##对比

| Label         | 梯度下降      | 正规方程  |
| ------------- |:-------------:| ---------:|
| 学习速率α     | 需要多次选取  | 不需要    |
| 多次迭代计算     | 需要       |   不需要  |
| 效率（特征多时） | 仍然高效   | 低效      |

***

##课后作业

第一次的编程作业主要熟悉一下Octave的语法和完成作业的环境，主要实现了梯度下降算法。
